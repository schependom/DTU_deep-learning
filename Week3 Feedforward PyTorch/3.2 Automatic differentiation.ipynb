{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily influenced or copied from https://github.com/pytorch/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd: automatic differentiation\n",
    "\n",
    "Central to all neural networks in PyTorch is the ``autograd`` package.\n",
    "Let’s first briefly visit this, and we will then go to training our first neural network.\n",
    "\n",
    "The `autograd` package **provides automatic differentiation for all operations on Tensors**.\n",
    "It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "Let us see this in more simple terms with some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor\n",
    "\n",
    "`torch.Tensor` is the central class of the package. Setting the attribute `.requires_grad` to `True` will make the tensor \"record\" all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into the `.grad` attribute.\n",
    "\n",
    "![autograd.Variable](https://github.com/DeepLearningDTU/02456-2025/tree/master/static_files/autograd-variable.png)\n",
    "\n",
    "- `data`\n",
    "- `grad`\n",
    "- `creator`\n",
    "\n",
    "There’s one more class which is very important for autograd implementation - a `Function`.\n",
    "\n",
    "`Tensor` and `Function` are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a `.grad_fn` attribute that references a `Function` that has created the `Tensor` (except for Tensors created by the user - their `grad_fn` is `None`).\n",
    "\n",
    "If you want to compute the derivatives, you can call `.backward()` on a Tensor. If `Tensor` is a scalar (i.e. it holds a one element data), you don’t need to specify any arguments to backward(), however if it has more elements, you need to specify a `gradient` argument that is a tensor of matching shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True) # requires_grad=True to track all operations on x\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a tensor operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2 # this operation is tracked\n",
    "print(y)\n",
    "# Each tensor has a `.grad_fn` attribute that references a `Function` that has created the `Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each tensor has a `.grad_fn` attribute that references a `Function` that has created the `Tensor`\n",
    "    - Except if the tensor was created by the user. In this case, `grad_fn` is `None`.\n",
    "    - But `y` was created as a result of an operation, so it has a `grad_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x130b37b20>\n",
      "The type of y.grad_fn is <class 'AddBackward0'>, a subclass of torch.autograd.Function\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)\n",
    "print(f\"The type of y.grad_fn is {type(y.grad_fn)}, a subclass of torch.autograd.Function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do more operations on y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "The operation that created z is <MulBackward0 object at 0x142f2f7f0>\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z)\n",
    "print(f\"The operation that created z is {z.grad_fn}\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments\n",
    "\n",
    "1. Create a Tensor that `requires_grad` of size (5, 5)\n",
    "2. Sum the values in the Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computation that created my_tensor_sum is <SumBackward0 object at 0x144f14f70>, a subclass of torch.autograd.Function\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "my_tensor = torch.rand(5,5, requires_grad=True)\n",
    "\n",
    "# 2. sum all values\n",
    "my_tensor_sum = my_tensor.sum()\n",
    "# my_tensor_sum = x_1 + x_2 + ... + x_5 (where x_i are vectors of size 5)\n",
    "# -> d(my_tensor_sum)/d(my_tensor) = [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], ..., [1, 1, 1, 1, 1] (5x5 matrix of ones)\n",
    "# -> In this matrix, x_ij = d(my_tensor_sum)/d(my_tensor[i,j])\n",
    "\n",
    "# 3. print the history\n",
    "print(f\"The computation that created my_tensor_sum is {my_tensor_sum.grad_fn}, a subclass of torch.autograd.Function\")\n",
    "\n",
    "# 4. Backprop\n",
    "my_tensor_sum.backward()\n",
    "\n",
    "print(my_tensor.grad) # print the gradients d(my_tensor_sum)/d(my_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gradients\n",
    "\n",
    "Let’s backprop now. Because `out` contains a single scalar, `out.backward()` is equivalent to `out.backward(torch.tensor([1.0]))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()\n",
    "\n",
    "# out = z.mean() = (y*y*3).mean() = ( (x+2)*(x+2)*3 ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print gradients d(out)/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have a matrix of `4.5`. Let’s denote the tensor `out` with $o$.\n",
    "\n",
    "We have:\n",
    "- $o = \\frac{1}{4}\\sum_i z_i$,\n",
    "- $z_i = 3(x_i+2)^2$\n",
    "- $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
    "\n",
    "Therefore, $\\frac{\\partial o}{\\partial x_i}\\rvert_{x_i=1} = \\frac{\\partial o}{\\partial z_i} \\frac{\\partial z_i}{\\partial x_i} \\rvert_{x_i=1} = \\frac{1}{4} \\sum_i \\frac{\\partial z_i}{\\partial x_i} =  \\frac{1}{4} \\sum_i 6 (x_i+2) \\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
    "\n",
    "You can do many crazy things with autograd!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1079.9368, -553.6485,  415.8031], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True) # normal distribution N(0,1)\n",
    "\n",
    "y = x * 2\n",
    "# -> data\n",
    "# -> grad\n",
    "# -> creator\n",
    "# print(f\"data: {y.data}, grad: {y.grad}, creator: {y.grad_fn}\")\n",
    "\n",
    "# keep doubling y until its norm is larger than 1000\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient dy/dx at x = tensor([ 2.1093, -1.0813,  0.8121]) is tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n",
      "Gradient dy/dy at y = tensor([1079.9368, -553.6485,  415.8031]) is tensor([1.0000e-01, 1.0000e+00, 1.0000e-04])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "\n",
    "y.retain_grad()  # retain gradients for non-leaf tensor x\n",
    "\n",
    "y.backward(gradients)\n",
    "\n",
    "# y.grad will not work because y is not a leaf tensor in the computation graph.\n",
    "# In PyTorch, only leaf tensors (those created by the user with requires_grad=True and not the result of an operation) have their .grad populated by default after backward().\n",
    "\n",
    "# y is the result of an operation (y = x * 2, etc.), so its .grad attribute will be None unless you explicitly call y.retain_grad() before backward().\n",
    "# For non-leaf tensors, gradients are not retained to save memory.\n",
    "\n",
    "print(f\"Gradient dy/dx at x = {x.data} is {x.grad}\")\n",
    "print(f\"Gradient dy/dy at y = {y.data} is {y.grad}\")  # This will be None unless y.retain_grad() was called before backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Click to see the ChatGPT explanation</summary>\n",
    "\n",
    "Alright, let’s unpack this carefully step by step — you’re mixing two subtly different things:\n",
    "\t1.\tDerivative $\\frac{dy}{dx}$ (the usual thing we want).\n",
    "\t2.\tDerivative $\\frac{dy}{dy}$, which sounds strange but makes sense in the context of backpropagation.\n",
    "\n",
    "⸻\n",
    "\n",
    "1. How $\\frac{dy}{dx}$ is calculated\n",
    "\n",
    "When you do:\n",
    "\n",
    "```python\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "```\n",
    "\n",
    "PyTorch builds a computation graph.\n",
    "\t•\tThe node y knows that it was produced by multiplying x by 2.\n",
    "\t•\tThe gradient rule stored in y.grad_fn is:\n",
    "$\\frac{\\partial y}{\\partial x} = 2.$\n",
    "\n",
    "Now, if later you call y.backward(gradients), the chain rule is applied:\n",
    "$\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x}$.\n",
    "\n",
    "So your x.grad stores exactly this.\n",
    "\n",
    "⸻\n",
    "\n",
    "2. What about $\\frac{dy}{dy}$?\n",
    "\n",
    "Here’s the trick: in backpropagation, the seed gradient is the derivative of a tensor with respect to itself.\n",
    "\n",
    "Formally:\n",
    "$\\frac{\\partial y}{\\partial y} = 1$.\n",
    "\n",
    "This is why, if you just do:\n",
    "\n",
    "```python\n",
    "y.backward()\n",
    "```\n",
    "\n",
    "PyTorch treats it as\n",
    "$\\frac{\\partial y}{\\partial y} = 1$,\n",
    "so it starts propagating a gradient of 1 backwards through the computation graph.\n",
    "\n",
    "If you instead pass an explicit vector of upstream gradients:\n",
    "\n",
    "```python\n",
    "y.backward(gradients)\n",
    "```\n",
    "\n",
    "you are telling PyTorch:\n",
    "$\\frac{\\partial L}{\\partial y} = \\text{gradients}$.\n",
    "\n",
    "So PyTorch doesn't assume $\\frac{dy}{dy} = 1$, but instead uses the vector you gave as the starting point for chain rule.\n",
    "\n",
    "⸻\n",
    "\n",
    "3. Why do we need gradients?\n",
    "\n",
    "Because in your case y is not a scalar (it’s a vector of size 3).\n",
    "\t•\tFor scalars, $\\frac{dy}{dy} = 1$ is unambiguous.\n",
    "\t•\tFor vectors, there isn't a single gradient; mathematically $\\frac{dy}{dy}$ would be the identity matrix, which is too big to store.\n",
    "\n",
    "So PyTorch requires you to provide the upstream gradient (a vector of the same shape as y) when you call .backward(). That’s what you did with:\n",
    "\n",
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "\n",
    "This acts like: “Suppose L = \\text{gradients}^T y. Compute \\nabla_x L.”\n",
    "\n",
    "⸻\n",
    "\n",
    "4. Why `retain_grad()` is needed\n",
    "\t•\tx is a leaf tensor (`requires_grad=True` created by you). PyTorch keeps its .grad.\n",
    "\t•\ty is a non-leaf tensor (result of operations). PyTorch frees its `.grad` by default to save memory.\n",
    "\t•\tIf you want to see gradients for y, you must call `y.retain_grad()` before `.backward()`.\n",
    "\n",
    "⸻\n",
    "\n",
    "✅ Summary:\n",
    "\t•\t$\\frac{dy}{dy} = 1$ for scalars, but for tensors PyTorch requires you to provide the upstream gradient.\n",
    "\t•\tThat’s why you pass gradients into `.backward()`.\n",
    "\t•\t`retain_grad()` is needed for non-leaf tensors if you want to inspect their .grad.\n",
    "\n",
    "⸻\n",
    "\n",
    "Do you want me to also draw the chain rule flow explicitly for your doubling loop (so you see exactly what multipliers accumulate in \\frac{dy}{dx})?\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later** \\\n",
    "*Documentation* \\\n",
    "`Tensor`: https://pytorch.org/docs/stable/tensors.html \\\n",
    "`Function`: http://pytorch.org/docs/autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments\n",
    "\n",
    "1. Define a tensor and set `requires_grad` to `True`\n",
    "3. Multiply the tensor by 2 and assign the result to a new python variable (i.e. `x = result`)\n",
    "4. Sum the variable's elements and assign to a new python variable\n",
    "5. Print the gradients of all the variables\n",
    "6. Now perform a backward pass on the last variable (NOTE: for each new python variable that you define, call `.retain_grad()`)\n",
    "7. Print all gradients again\n",
    "  - what did you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3490, 0.6798, 0.9400],\n",
      "        [0.9397, 0.5306, 0.6140]], requires_grad=True)\n",
      "tensor([[0.6979, 1.3597, 1.8801],\n",
      "        [1.8794, 1.0612, 1.2281]], grad_fn=<MulBackward0>)\n",
      "\n",
      "\n",
      "Before backward pass (no gradients computed):\n",
      "\n",
      "Gradient of my_sum w.r.t. my_tensor: None\n",
      "Gradient of my_sum w.r.t. x: None\n",
      "Gradient of my_sum w.r.t. itself: None\n",
      "\n",
      "\n",
      "After backward pass (gradients computed):\n",
      "\n",
      "Gradient of my_sum w.r.t. my_tensor: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "Gradient of my_sum w.r.t. x: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Gradient of my_sum w.r.t. itself: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/qw26xkk51853rtytqd9ns_5r0000gn/T/ipykernel_4871/2535971379.py:17: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(f\"Gradient of my_sum w.r.t. x: {x.grad}\")\n",
      "/var/folders/dn/qw26xkk51853rtytqd9ns_5r0000gn/T/ipykernel_4871/2535971379.py:18: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(f\"Gradient of my_sum w.r.t. itself: {my_sum.grad}\")\n",
      "/var/folders/dn/qw26xkk51853rtytqd9ns_5r0000gn/T/ipykernel_4871/2535971379.py:29: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(f\"Gradient of my_sum w.r.t. itself: {my_sum.grad}\") # result = root node, so it does not have any gradients\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(2,3, requires_grad=True)\n",
    "\n",
    "print(my_tensor)\n",
    "\n",
    "# multiply by two and assign the result to a new variable\n",
    "x = my_tensor.multiply(2)\n",
    "\n",
    "print(x)\n",
    "\n",
    "# sum the variables elements\n",
    "my_sum = x.sum()\n",
    "\n",
    "print(\"\\n\\nBefore backward pass (no gradients computed):\\n\")\n",
    "\n",
    "# print the gradients of all the variables\n",
    "print(f\"Gradient of my_sum w.r.t. my_tensor: {my_tensor.grad}\")\n",
    "print(f\"Gradient of my_sum w.r.t. x: {x.grad}\")\n",
    "print(f\"Gradient of my_sum w.r.t. itself: {my_sum.grad}\")\n",
    "\n",
    "print(\"\\n\\nAfter backward pass (gradients computed):\\n\")\n",
    "\n",
    "# for intermediate steps, we can call .retain_grad() to keep track of the gradients\n",
    "x.retain_grad()\n",
    "\n",
    "# perform a backward pass on the last variable\n",
    "my_sum.backward()\n",
    "print(f\"Gradient of my_sum w.r.t. my_tensor: {my_tensor.grad}\") # input always has gradients\n",
    "print(f\"Gradient of my_sum w.r.t. x: {x.grad}\") # x is not a leaf node but we called x.retain_grad()\n",
    "print(f\"Gradient of my_sum w.r.t. itself: {my_sum.grad}\") # result = root node, so it does not have any gradients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTU_deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
